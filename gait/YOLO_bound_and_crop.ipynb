{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Most of this code is from the official YOLOv8 [tutorial](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb#scrollTo=tdSMcABDNKW-)."
      ],
      "metadata": {
        "id": "cuwnJCF7uNyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install YOLOv8"
      ],
      "metadata": {
        "id": "8Sx3eIMyuIPc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdSMcABDNKW-"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics==8.0.196\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "Xc1OkZbMb46p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model = YOLO('yolov8m.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3J8sNnJwdR"
      },
      "source": [
        "## Extract frames for all videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSQMAcIaNYWS"
      },
      "outputs": [],
      "source": [
        "os.mkdir(\"/content/frames/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTAxrlCpJwMq"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "path = \"/content/drive/MyDrive/ataxia_dataset/raw_videos_ver2/\"\n",
        "# Extract frames for all videos & save them\n",
        "for video in os.listdir(path):\n",
        "  if \".mov\" not in video:\n",
        "    continue\n",
        "  else:\n",
        "    # Break the video into frames at 30 fps\n",
        "    if os.path.exists(f\"/content/frames/{video[:-4]}/\"):\n",
        "      continue\n",
        "    os.mkdir(f\"/content/frames/{video[:-4]}/\")\n",
        "    command = [\"ffmpeg\", \"-i\", os.path.join(path, video), \"-vf\", \"fps=30\", f\"/content/frames/{video[:-4]}/output_%05d.jpg\"]\n",
        "    out = subprocess.run(command, stderr=subprocess.PIPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterate over videos sequentially, get bounding boxes & resize"
      ],
      "metadata": {
        "id": "TTnt6F24u21J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"/content/updated_frames/\")\n",
        "os.mkdir(\"/content/updated_videos/\")"
      ],
      "metadata": {
        "id": "hIo3HDFNEIl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP_LIST = [28, 29, 31, 32, 33, 36, 38, 41, 45, 47, 48, 50, 51, 52, 53, 54, 55, 141]"
      ],
      "metadata": {
        "id": "hEmgMjlcu1t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NORMALIZED_HEIGHT = 800\n",
        "cur_video_num = 2\n",
        "\n",
        "for cur_video_num in tqdm(range(0, 151)):\n",
        "  if cur_video_num in SP_LIST:\n",
        "    make_vid = [\"ffmpeg\", \"-framerate\", \"30\", \"-pattern_type\", \"glob\", \"-i\", f'/content/frames/{cur_video_num}/*.jpg', \\\n",
        "                \"-vf\", \"pad=ceil(iw/2)*2:ceil(ih/2)*2\", \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \\\n",
        "                f\"/content/updated_videos/out_{cur_video_num}.mp4\"]\n",
        "    out = subprocess.run(make_vid, stderr=subprocess.PIPE)\n",
        "    continue\n",
        "  if not os.path.exists(f\"/content/frames/{cur_video_num}/\"):\n",
        "    continue\n",
        "  for frame in os.listdir(f\"/content/frames/{cur_video_num}/\"):\n",
        "    if os.path.exists(f\"/content/updated_frames/{cur_video_num}/updated_{frame}\"):\n",
        "      continue\n",
        "    # Define input image\n",
        "    image = cv2.imread(f\"/content/frames/{cur_video_num}/{frame}\")\n",
        "\n",
        "    # Get image dimensions\n",
        "    (height, width) = image.shape[:2]\n",
        "\n",
        "    # Get bounding boxes around objects\n",
        "    results = model.predict(source=image, iou=0.7, verbose=False)\n",
        "\n",
        "    # Initialize the final placeholders\n",
        "    max_conf = -1\n",
        "    max_conf_person = None\n",
        "\n",
        "    # Loop over the detections\n",
        "    for result in results:\n",
        "      for (xywh, confidence, cls) in zip(result.boxes.xywh, result.boxes.conf, result.boxes.cls):\n",
        "\n",
        "        if cls == 0 and confidence > max_conf:\n",
        "            # Object detected\n",
        "            center_x = int(xywh[0]) # * width\n",
        "            center_y = int(xywh[1]) # * height\n",
        "            w = int(xywh[2]) # * width\n",
        "            h = int(xywh[3]) # * height\n",
        "\n",
        "            # Rectangle coordinates\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "\n",
        "            # Add the detection to the list of people\n",
        "            max_conf_person = (x, y, w, h)\n",
        "            max_conf = confidence\n",
        "\n",
        "    if max_conf_person == None:\n",
        "      print(f\"Error at frame : {frame} in video : {cur_video_num}.\")\n",
        "      continue\n",
        "    x, y, w, h = max_conf_person\n",
        "    cropped_image = image[y:y+h, x:x+w]\n",
        "    aspect_ratio = w/h\n",
        "    new_width = int(NORMALIZED_HEIGHT * aspect_ratio)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_image = cv2.resize(cropped_image, (new_width, NORMALIZED_HEIGHT))\n",
        "\n",
        "    if not os.path.exists(f\"/content/updated_frames/{cur_video_num}/\"):\n",
        "      os.mkdir(f\"/content/updated_frames/{cur_video_num}/\")\n",
        "    cv2.imwrite(f\"/content/updated_frames/{cur_video_num}/updated_{frame}\", resized_image)\n",
        "  make_vid = [\"ffmpeg\", \"-framerate\", \"30\", \"-pattern_type\", \"glob\", \"-i\", f'/content/updated_frames/{cur_video_num}/*.jpg', \\\n",
        "              \"-vf\", \"pad=ceil(iw/2)*2:ceil(ih/2)*2\", \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \\\n",
        "              f\"/content/updated_videos/out_{cur_video_num}.mp4\"]\n",
        "  out = subprocess.run(make_vid, stderr=subprocess.PIPE)"
      ],
      "metadata": {
        "id": "dYwCa38Au-NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save `updated_videos/`\n",
        "Zipping just to be safe."
      ],
      "metadata": {
        "id": "bnTmzFVB0dMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r updated_videos.zip updated_videos/"
      ],
      "metadata": {
        "id": "UG1L_mms0fhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(f\"/content/updated_videos/\", \"/content/drive/MyDrive/ataxia_dataset/\")"
      ],
      "metadata": {
        "id": "akLFTVQs0mL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thanks!"
      ],
      "metadata": {
        "id": "a2lcEdU_3smN"
      }
    }
  ]
}